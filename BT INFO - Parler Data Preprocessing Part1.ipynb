{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parler DATA PREPROCESSING Part 1\n",
    "\n",
    "Data source: Aliapoulios, M., Bevensee, E., Blackburn, J., Bradlyn, B., De Cristofaro, E., Stringhini, G., & Zannettou, S. (2021, May). A Large Open Dataset from the Parler Social Network. In ICWSM (pp. 943-951).\n",
    "\n",
    "1. Read NDJSON file with Parler data as pandas dataframe \n",
    "2. Remove unuseful columns = dimension reduction (columns) -> only [body] and [createdAtformatted] left\n",
    "3. Filter out null values found in [body] of parleys = dimension reduction (rows)\n",
    "4. Filter out parleys not in relevant time period = dimension reduction (rows) -> only Nov 2020, Dec 2020 and Jan 2021 left\n",
    "5. Filter out [body] of parleys in languages except English = dimension reduction (rows)\n",
    "6. Remove unuseful time info from [createdAtformatted] column -> only date info left \n",
    "7. Save pandas dataframe containing only useful info (no index) as CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read NDJSON file as pandas dataframe\n",
    "\n",
    "parler_df = pd.read_json('D:\\\\bachelors_thesis\\Datasets\\parler_data\\parler_data000000000041.ndjson', lines = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['comments', 'body', 'bodywithurls', 'createdAt', 'createdAtformatted',\n",
      "       'creator', 'datatype', 'depth', 'depthRaw', 'followers', 'following',\n",
      "       'hashtags', 'id', 'lastseents', 'links', 'media', 'parent', 'posts',\n",
      "       'sensitive', 'upvotes', 'urls', 'username', 'verified', 'article',\n",
      "       'impressions', 'preview', 'reposts', 'state', 'shareLink', 'color',\n",
      "       'commentDepth', 'controversy', 'conversation', 'downvotes', 'post',\n",
      "       'replyingTo', 'score', 'isPrimary'],\n",
      "      dtype='object')\n",
      "Dimension of whole dataframe: (1095543, 38)\n",
      "\n",
      "Index(['body', 'createdAtformatted'], dtype='object')\n",
      "Dimension of dataframe after removing columns: (1095543, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Remove unuseful columns = dimension reduction (columns) -> only [body] and [createdAtformatted] left\n",
    "\n",
    "print(parler_df.columns)\n",
    "print('Dimension of whole dataframe: ' + str(parler_df.shape) + '\\n') # df.shape -> (rows, columns)\n",
    "\n",
    "# final_df_1 = pd.DataFrame()\n",
    "# final_df_1['body'] = df['body'].copy()\n",
    "# final_df_1['createdAtformatted'] = df['createdAtformatted'].copy()\n",
    "# parler_df.drop(parler_df.iloc[:, 2:38], inplace = True, axis = 1) # remove all columns between column index 2 to 38\n",
    "# parler_df.drop(['comments'], inplace = True, axis = 1)            # remove first column\n",
    "parler_df.drop(parler_df.iloc[:, 5:38], inplace = True, axis = 1)   # remove all columns between column index 5 to 38\n",
    "parler_df.drop(['comments'], inplace = True, axis = 1)              # remove column nr. 0\n",
    "parler_df.drop(['bodywithurls'], inplace = True, axis = 1)          # remove column nr. 2\n",
    "parler_df.drop(['createdAt'], inplace = True, axis = 1)             # remove column nr. 3\n",
    "\n",
    "print(parler_df.columns)\n",
    "print('Dimension of dataframe after removing columns: ' + str(parler_df.shape) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of dataframe: (1095543, 2)\n",
      "        body       createdAtformatted\n",
      "0             2019-12-22 05:13:59 UTC\n",
      "1             2020-11-05 15:45:56 UTC\n",
      "2             2020-12-04 23:23:36 UTC\n",
      "3             2020-11-11 18:36:20 UTC\n",
      "4             2021-01-08 23:17:40 UTC\n",
      "...      ...                      ...\n",
      "1095538       2020-12-22 21:51:11 UTC\n",
      "1095539       2020-11-02 00:56:02 UTC\n",
      "1095540       2019-09-23 05:07:10 UTC\n",
      "1095541       2020-11-11 00:53:16 UTC\n",
      "1095542       2020-12-20 15:18:33 UTC\n",
      "\n",
      "[1095543 rows x 2 columns]\n",
      "\n",
      "Dimension of dataframe after filtering out null values: (637020, 2)\n",
      "                                                      body  \\\n",
      "19       We have the Sorriest FBI in the history of any...   \n",
      "48       Agree 100% #wakeupamerica #obamamostcorruptpot...   \n",
      "49       Human 2.0 Warning: Doctor Issues Wake Up Call ...   \n",
      "176      This is massive this is big this is what you f...   \n",
      "290                        #trump2020 #bestpresidentever45   \n",
      "...                                                    ...   \n",
      "1095508  While that’s a good thing, it makes me wonder ...   \n",
      "1095524                          Please put this guy away.   \n",
      "1095531                     Hey it totally works for them.   \n",
      "1095534                    See? Unity works... #TakeAStand   \n",
      "1095536                        I am ready first the truth.   \n",
      "\n",
      "              createdAtformatted  \n",
      "19       2020-10-03 11:25:19 UTC  \n",
      "48       2020-06-30 19:52:34 UTC  \n",
      "49       2020-10-25 22:25:28 UTC  \n",
      "176      2020-12-23 05:00:55 UTC  \n",
      "290      2020-06-30 21:23:14 UTC  \n",
      "...                          ...  \n",
      "1095508  2020-07-02 21:24:06 UTC  \n",
      "1095524  2020-10-28 17:23:10 UTC  \n",
      "1095531  2020-09-24 20:34:56 UTC  \n",
      "1095534  2020-07-27 00:21:44 UTC  \n",
      "1095536  2020-12-20 03:57:34 UTC  \n",
      "\n",
      "[637020 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3. Filter out null values found in [body] of parleys = dimension reduction (rows)\n",
    "\n",
    "print('Dimension of dataframe: ' + str(parler_df.shape)) \n",
    "print(parler_df) \n",
    "\n",
    "parler_df['body'].replace(\"\", np.nan, inplace=True)\n",
    "parler_df.dropna(subset=['body'], inplace=True)\n",
    "# parler_df.reset_index(drop=True, inplace=True)\n",
    "# parler_df.drop_duplicates(subset = ['body'], inplace=True, keep='first'/'last'/False)\n",
    "\n",
    "print('\\n'  + 'Dimension of dataframe after filtering out null values: ' + str(parler_df.shape)) \n",
    "print(parler_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of dataframe before: (637020, 2)\n",
      "                                                      body  \\\n",
      "19       We have the Sorriest FBI in the history of any...   \n",
      "48       Agree 100% #wakeupamerica #obamamostcorruptpot...   \n",
      "49       Human 2.0 Warning: Doctor Issues Wake Up Call ...   \n",
      "176      This is massive this is big this is what you f...   \n",
      "290                        #trump2020 #bestpresidentever45   \n",
      "...                                                    ...   \n",
      "1095508  While that’s a good thing, it makes me wonder ...   \n",
      "1095524                          Please put this guy away.   \n",
      "1095531                     Hey it totally works for them.   \n",
      "1095534                    See? Unity works... #TakeAStand   \n",
      "1095536                        I am ready first the truth.   \n",
      "\n",
      "              createdAtformatted  \n",
      "19       2020-10-03 11:25:19 UTC  \n",
      "48       2020-06-30 19:52:34 UTC  \n",
      "49       2020-10-25 22:25:28 UTC  \n",
      "176      2020-12-23 05:00:55 UTC  \n",
      "290      2020-06-30 21:23:14 UTC  \n",
      "...                          ...  \n",
      "1095508  2020-07-02 21:24:06 UTC  \n",
      "1095524  2020-10-28 17:23:10 UTC  \n",
      "1095531  2020-09-24 20:34:56 UTC  \n",
      "1095534  2020-07-27 00:21:44 UTC  \n",
      "1095536  2020-12-20 03:57:34 UTC  \n",
      "\n",
      "[637020 rows x 2 columns]\n",
      "Dimension of dataframe with tweets from relevant time period only: (353028, 2)\n",
      "                                                      body  \\\n",
      "176      This is massive this is big this is what you f...   \n",
      "345      #biden is wearing a bullet proof vest 🤣😂🤣😂 Ful...   \n",
      "561           Absofreakinglutely!!! Tear that shit down!!!   \n",
      "686      @Joebwinner And you are correct.. There are li...   \n",
      "688      @factsRus I guess that’s why 15 CIA operative ...   \n",
      "...                                                    ...   \n",
      "1095448                          The reckoning approaches.   \n",
      "1095450  Fuck this piece of shit. And fuck anyone who d...   \n",
      "1095463                           🙌🏼🙌🏼🙌🏼🙌🏼🙌🏼🙌🏼🇺🇸🇺🇸🇺🇸🇺🇸🇺🇸🇺🇸   \n",
      "1095465  Thank you Ricky !! ❤️You may loose some no goo...   \n",
      "1095536                        I am ready first the truth.   \n",
      "\n",
      "              createdAtformatted  \n",
      "176      2020-12-23 05:00:55 UTC  \n",
      "345      2020-12-02 23:36:57 UTC  \n",
      "561      2021-01-03 05:36:11 UTC  \n",
      "686      2020-11-24 01:03:33 UTC  \n",
      "688      2020-11-30 05:49:11 UTC  \n",
      "...                          ...  \n",
      "1095448  2020-12-05 17:37:29 UTC  \n",
      "1095450  2020-12-24 05:15:29 UTC  \n",
      "1095463  2020-11-13 17:06:58 UTC  \n",
      "1095465  2020-11-21 15:14:57 UTC  \n",
      "1095536  2020-12-20 03:57:34 UTC  \n",
      "\n",
      "[353028 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 4. Filter out parleys not in relevant time period = dimension reduction (rows) -> only Nov 2020, Dec 2020 and Jan 2021 left\n",
    "\n",
    "def check_date(string):\n",
    "    if ( (((string.split('-'))[0] == '2020') and ((string.split('-'))[1] == '11'))          # November 2020\n",
    "        or (((string.split('-'))[0] == '2020') and ((string.split('-'))[1] == '12'))        # December 2020\n",
    "        or (((string.split('-'))[0] == '2021') and ((string.split('-'))[1] == '01')) ):     # January  2021\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "print('Dimension of dataframe before: ' + str(parler_df.shape)) \n",
    "print(parler_df)\n",
    "\n",
    "parler_df['appropiateDate'] = parler_df['createdAtformatted'].apply(check_date)\n",
    "# parler_df.drop(parler_df[parler_df['appropiateDate'] == False].index, inplace=True)\n",
    "parler_df = parler_df[parler_df['appropiateDate'] == True]\n",
    "parler_df.drop(['appropiateDate'], inplace = True, axis = 1)          \n",
    "\n",
    "print('Dimension of dataframe with parleys from relevant time period only: ' + str(parler_df.shape)) \n",
    "print(parler_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of dataframe before: (353028, 2)\n",
      "Dimension of dataframe with tweets in English only: (353028, 3)\n",
      "                                                      body  \\\n",
      "176      This is massive this is big this is what you f...   \n",
      "345      #biden is wearing a bullet proof vest 🤣😂🤣😂 Ful...   \n",
      "561           Absofreakinglutely!!! Tear that shit down!!!   \n",
      "686      @Joebwinner And you are correct.. There are li...   \n",
      "688      @factsRus I guess that’s why 15 CIA operative ...   \n",
      "...                                                    ...   \n",
      "1095448                          The reckoning approaches.   \n",
      "1095450  Fuck this piece of shit. And fuck anyone who d...   \n",
      "1095463                           🙌🏼🙌🏼🙌🏼🙌🏼🙌🏼🙌🏼🇺🇸🇺🇸🇺🇸🇺🇸🇺🇸🇺🇸   \n",
      "1095465  Thank you Ricky !! ❤️You may loose some no goo...   \n",
      "1095536                        I am ready first the truth.   \n",
      "\n",
      "              createdAtformatted language  \n",
      "176      2020-12-23 05:00:55 UTC       en  \n",
      "345      2020-12-02 23:36:57 UTC     None  \n",
      "561      2021-01-03 05:36:11 UTC       en  \n",
      "686      2020-11-24 01:03:33 UTC       en  \n",
      "688      2020-11-30 05:49:11 UTC       en  \n",
      "...                          ...      ...  \n",
      "1095448  2020-12-05 17:37:29 UTC       en  \n",
      "1095450  2020-12-24 05:15:29 UTC       en  \n",
      "1095463  2020-11-13 17:06:58 UTC       dv  \n",
      "1095465  2020-11-21 15:14:57 UTC       en  \n",
      "1095536  2020-12-20 03:57:34 UTC       en  \n",
      "\n",
      "[353028 rows x 3 columns]\n",
      "                                                      body  \\\n",
      "176      This is massive this is big this is what you f...   \n",
      "561           Absofreakinglutely!!! Tear that shit down!!!   \n",
      "686      @Joebwinner And you are correct.. There are li...   \n",
      "688      @factsRus I guess that’s why 15 CIA operative ...   \n",
      "691                           @JennieWrennnn Your welcome.   \n",
      "...                                                    ...   \n",
      "1095400  Ok, your beautiful wife who is currently livin...   \n",
      "1095448                          The reckoning approaches.   \n",
      "1095450  Fuck this piece of shit. And fuck anyone who d...   \n",
      "1095465  Thank you Ricky !! ❤️You may loose some no goo...   \n",
      "1095536                        I am ready first the truth.   \n",
      "\n",
      "              createdAtformatted  \n",
      "176      2020-12-23 05:00:55 UTC  \n",
      "561      2021-01-03 05:36:11 UTC  \n",
      "686      2020-11-24 01:03:33 UTC  \n",
      "688      2020-11-30 05:49:11 UTC  \n",
      "691      2020-11-01 23:36:45 UTC  \n",
      "...                          ...  \n",
      "1095400  2020-12-15 13:43:19 UTC  \n",
      "1095448  2020-12-05 17:37:29 UTC  \n",
      "1095450  2020-12-24 05:15:29 UTC  \n",
      "1095465  2020-11-21 15:14:57 UTC  \n",
      "1095536  2020-12-20 03:57:34 UTC  \n",
      "\n",
      "[294295 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 5. Filter out [body] of parleys in languages except English = dimension reduction (rows)\n",
    "\n",
    "import fasttext\n",
    "model = fasttext.load_model(\"lid.176.ftz\")\n",
    "\n",
    "def fast_detect(msg):\n",
    "    try:\n",
    "        ln = model.predict(msg)[0][0].split(\"__\")[2] \n",
    "    except Exception as e:\n",
    "        ln = None\n",
    "    return ln\n",
    "\n",
    "print('Dimension of dataframe before: ' + str(parler_df.shape)) \n",
    "parler_df['language'] = parler_df['body'].apply(fast_detect)\n",
    "print('Dimension of dataframe with parleys in English only: ' + str(parler_df.shape)) \n",
    "\n",
    "print(parler_df)\n",
    "parler_df.drop(parler_df[parler_df['language'] != 'en'].index, inplace=True)\n",
    "parler_df.drop(['language'], inplace = True, axis = 1)          \n",
    "print(parler_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176        2020-12-23 05:00:55 UTC\n",
      "561        2021-01-03 05:36:11 UTC\n",
      "686        2020-11-24 01:03:33 UTC\n",
      "688        2020-11-30 05:49:11 UTC\n",
      "691        2020-11-01 23:36:45 UTC\n",
      "                    ...           \n",
      "1095400    2020-12-15 13:43:19 UTC\n",
      "1095448    2020-12-05 17:37:29 UTC\n",
      "1095450    2020-12-24 05:15:29 UTC\n",
      "1095465    2020-11-21 15:14:57 UTC\n",
      "1095536    2020-12-20 03:57:34 UTC\n",
      "Name: createdAtformatted, Length: 294295, dtype: object\n",
      "176        2020-12-23\n",
      "561        2021-01-03\n",
      "686        2020-11-24\n",
      "688        2020-11-30\n",
      "691        2020-11-01\n",
      "              ...    \n",
      "1095400    2020-12-15\n",
      "1095448    2020-12-05\n",
      "1095450    2020-12-24\n",
      "1095465    2020-11-21\n",
      "1095536    2020-12-20\n",
      "Name: createdAtformatted, Length: 294295, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 6. Remove unuseful time info from [createdAtformatted] column -> only date info left \n",
    "\n",
    "print(parler_df['createdAtformatted'])\n",
    "parler_df['createdAtformatted'] = parler_df['createdAtformatted'].str.split(n = 0, expand = False).str[0]\n",
    "print(parler_df['createdAtformatted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Save pandas dataframe containing only useful info (no index) as CSV file\n",
    "\n",
    "parler_df.to_csv('parler_df_041_dates_before.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
