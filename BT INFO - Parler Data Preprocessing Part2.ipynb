{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33a24615",
   "metadata": {},
   "source": [
    "Parler DATA PREPROCESSING Part 2\n",
    "\n",
    "8. Read CSV file containing only useful info (no index) as pandas dataframe\n",
    "9. Convert [body] of parleys to lowercase\n",
    "10. Remove emojis from [body] of parleys (demoji library)\n",
    "11. Remove English and Spanish stopwords from [body] of parleys (using stopwords from nltk corpus)\n",
    "12. Expand contractions from [body] of parleys (contractions library) (ex: you’re => you are) \n",
    "13. Remove punctuation from [body] of parleys (using string.punctuation)\n",
    "14. Remove numbers from [body] of parleys (re = regular expression library)\n",
    "15. Lemmatization of [body] of parleys (using WordNetLemmatizer from nltk) (ex: says => say) \n",
    "16. Remove words shorter than 3 characters from [body] of parleys\n",
    "17. Filter out null values found in [body] of parleys once more = dimension reduction (rows)\n",
    "18. Save pandas dataframe without index after preprocessing as CSV file\n",
    "19. Save pandas dataframes without index for each month after preprocessing as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5892eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "854b4c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     body createdAtformatted\n",
      "0       This is massive this is big this is what you f...         2020-12-23\n",
      "1            Absofreakinglutely!!! Tear that shit down!!!         2021-01-03\n",
      "2       @Joebwinner And you are correct.. There are li...         2020-11-24\n",
      "3       @factsRus I guess that’s why 15 CIA operative ...         2020-11-30\n",
      "4                            @JennieWrennnn Your welcome.         2020-11-01\n",
      "...                                                   ...                ...\n",
      "294290  Ok, your beautiful wife who is currently livin...         2020-12-15\n",
      "294291                          The reckoning approaches.         2020-12-05\n",
      "294292  Fuck this piece of shit. And fuck anyone who d...         2020-12-24\n",
      "294293  Thank you Ricky !! ❤️You may loose some no goo...         2020-11-21\n",
      "294294                        I am ready first the truth.         2020-12-20\n",
      "\n",
      "[294295 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 8. Read CSV file containing only useful info (no index) as pandas dataframe\n",
    "\n",
    "parler_df = pd.read_csv('C:\\\\Users\\\\cosmi\\\\Desktop\\\\ANDREEA\\\\bachelors-thesis\\\\parler_df_041_dates_before.csv')\n",
    "print(parler_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b26a7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         This is massive this is big this is what you f...\n",
      "1              Absofreakinglutely!!! Tear that shit down!!!\n",
      "2         @Joebwinner And you are correct.. There are li...\n",
      "3         @factsRus I guess that’s why 15 CIA operative ...\n",
      "4                              @JennieWrennnn Your welcome.\n",
      "                                ...                        \n",
      "294290    Ok, your beautiful wife who is currently livin...\n",
      "294291                            The reckoning approaches.\n",
      "294292    Fuck this piece of shit. And fuck anyone who d...\n",
      "294293    Thank you Ricky !! ❤️You may loose some no goo...\n",
      "294294                          I am ready first the truth.\n",
      "Name: body, Length: 294295, dtype: object\n",
      "0         this is massive this is big this is what you f...\n",
      "1              absofreakinglutely!!! tear that shit down!!!\n",
      "2         @joebwinner and you are correct.. there are li...\n",
      "3         @factsrus i guess that’s why 15 cia operative ...\n",
      "4                              @jenniewrennnn your welcome.\n",
      "                                ...                        \n",
      "294290    ok, your beautiful wife who is currently livin...\n",
      "294291                            the reckoning approaches.\n",
      "294292    fuck this piece of shit. and fuck anyone who d...\n",
      "294293    thank you ricky !! ❤️you may loose some no goo...\n",
      "294294                          i am ready first the truth.\n",
      "Name: body, Length: 294295, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 9. Convert [body] of parleys to lowercase\n",
    "\n",
    "print(parler_df['body'])\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: ' '.join([w.lower() for w in x.split()]))\n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c7481e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         this is massive this is big this is what you f...\n",
      "1              absofreakinglutely!!! tear that shit down!!!\n",
      "2         @joebwinner and you are correct.. there are li...\n",
      "3         @factsrus i guess that’s why 15 cia operative ...\n",
      "4                              @jenniewrennnn your welcome.\n",
      "                                ...                        \n",
      "294290    ok, your beautiful wife who is currently livin...\n",
      "294291                            the reckoning approaches.\n",
      "294292    fuck this piece of shit. and fuck anyone who d...\n",
      "294293    thank you ricky !! ❤️you may loose some no goo...\n",
      "294294                          i am ready first the truth.\n",
      "Name: body, Length: 294295, dtype: object\n",
      "0         this is massive this is big this is what you f...\n",
      "1              absofreakinglutely!!! tear that shit down!!!\n",
      "2         @joebwinner and you are correct.. there are li...\n",
      "3         @factsrus i guess that’s why 15 cia operative ...\n",
      "4                              @jenniewrennnn your welcome.\n",
      "                                ...                        \n",
      "294290    ok, your beautiful wife who is currently livin...\n",
      "294291                            the reckoning approaches.\n",
      "294292    fuck this piece of shit. and fuck anyone who d...\n",
      "294293    thank you ricky !! you may loose some no good ...\n",
      "294294                          i am ready first the truth.\n",
      "Name: body, Length: 294295, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 10. Remove emojis from [body] of parleys (demoji library)\n",
    "\n",
    "import demoji\n",
    "print(parler_df['body'])\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: demoji.replace(x, \"\"))\n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "433575e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         this is massive this is big this is what you f...\n",
      "1              absofreakinglutely!!! tear that shit down!!!\n",
      "2         @joebwinner and you are correct.. there are li...\n",
      "3         @factsrus i guess that’s why 15 cia operative ...\n",
      "4                              @jenniewrennnn your welcome.\n",
      "                                ...                        \n",
      "294290    ok, your beautiful wife who is currently livin...\n",
      "294291                            the reckoning approaches.\n",
      "294292    fuck this piece of shit. and fuck anyone who d...\n",
      "294293    thank you ricky !! you may loose some no good ...\n",
      "294294                          i am ready first the truth.\n",
      "Name: body, Length: 294295, dtype: object\n",
      "0         massive big find really dig! incriminating evi...\n",
      "1                   absofreakinglutely!!! tear shit down!!!\n",
      "2         @joebwinner correct.. literally conservatives ...\n",
      "3         @factsrus guess that’s 15 cia operative killed...\n",
      "4                                   @jenniewrennnn welcome.\n",
      "                                ...                        \n",
      "294290    ok, beautiful wife currently living free count...\n",
      "294291                                reckoning approaches.\n",
      "294292    fuck piece shit. fuck anyone disrespects count...\n",
      "294293    thank ricky !! may loose good liberals hollywo...\n",
      "294294                                   ready first truth.\n",
      "Name: body, Length: 294295, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 11. Remove English and Spanish stopwords from [body] of parleys (using stopwords from nltk corpus)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "english_stop_words = [sw for sw in nltk.corpus.stopwords.words('english') if sw not in ['not', 'no']]\n",
    "english_stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "# print(english_stop_words)\n",
    "spanish_stop_words = stopwords.words('spanish')\n",
    "# print(spanish_stop_words)\n",
    "\n",
    "print(parler_df['body'])\n",
    "\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: ' '.join([w for w in x.split() if w not in english_stop_words]))\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: ' '.join([w for w in x.split() if w not in spanish_stop_words]))\n",
    "\n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eb53256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         massive big find really dig! incriminating evi...\n",
      "1                   absofreakinglutely!!! tear shit down!!!\n",
      "2         @joebwinner correct.. literally conservatives ...\n",
      "3         @factsrus guess that’s 15 cia operative killed...\n",
      "4                                   @jenniewrennnn welcome.\n",
      "                                ...                        \n",
      "294290    ok, beautiful wife currently living free count...\n",
      "294291                                reckoning approaches.\n",
      "294292    fuck piece shit. fuck anyone disrespects count...\n",
      "294293    thank ricky !! may loose good liberals hollywo...\n",
      "294294                                   ready first truth.\n",
      "Name: body, Length: 294295, dtype: object\n",
      "0         massive big find really dig! incriminating evi...\n",
      "1                   absofreakinglutely!!! tear shit down!!!\n",
      "2         @joebwinner correct.. literally conservatives ...\n",
      "3         @factsrus guess that is 15 cia operative kille...\n",
      "4                                   @jenniewrennnn welcome.\n",
      "                                ...                        \n",
      "294290    ok, beautiful wife currently living free count...\n",
      "294291                                reckoning approaches.\n",
      "294292    fuck piece shit. fuck anyone disrespects count...\n",
      "294293    thank ricky !! may loose good liberals hollywo...\n",
      "294294                                   ready first truth.\n",
      "Name: body, Length: 294295, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 12. Expand contractions from [body] of parleys (contractions library) (ex: you’re => you are) \n",
    "\n",
    "import contractions\n",
    "print(parler_df['body'])\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: ' '.join([contractions.fix(word) for word in x.split()]))\n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a11d96cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         massive big find really dig! incriminating evi...\n",
      "1                   absofreakinglutely!!! tear shit down!!!\n",
      "2         @joebwinner correct.. literally conservatives ...\n",
      "3         @factsrus guess that is 15 cia operative kille...\n",
      "4                                   @jenniewrennnn welcome.\n",
      "                                ...                        \n",
      "294290    ok, beautiful wife currently living free count...\n",
      "294291                                reckoning approaches.\n",
      "294292    fuck piece shit. fuck anyone disrespects count...\n",
      "294293    thank ricky !! may loose good liberals hollywo...\n",
      "294294                                   ready first truth.\n",
      "Name: body, Length: 294295, dtype: object\n",
      "0         massive big find really dig incriminating evid...\n",
      "1                         absofreakinglutely tear shit down\n",
      "2         joebwinner correct literally conservatives bur...\n",
      "3         factsrus guess that is 15 cia operative killed...\n",
      "4                                     jenniewrennnn welcome\n",
      "                                ...                        \n",
      "294290    ok beautiful wife currently living free countr...\n",
      "294291                                 reckoning approaches\n",
      "294292    fuck piece shit fuck anyone disrespects countr...\n",
      "294293    thank ricky  may loose good liberals hollywood...\n",
      "294294                                    ready first truth\n",
      "Name: body, Length: 294295, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 13. Remove punctuation from [body] of parleys (using string.punctuation)\n",
    "\n",
    "import string \n",
    "print(parler_df['body'])\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: ''.join([i for i in x if i not in string.punctuation]))\n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42613ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         massive big find really dig incriminating evid...\n",
      "1                         absofreakinglutely tear shit down\n",
      "2         joebwinner correct literally conservatives bur...\n",
      "3         factsrus guess that is 15 cia operative killed...\n",
      "4                                     jenniewrennnn welcome\n",
      "                                ...                        \n",
      "294290    ok beautiful wife currently living free countr...\n",
      "294291                                 reckoning approaches\n",
      "294292    fuck piece shit fuck anyone disrespects countr...\n",
      "294293    thank ricky  may loose good liberals hollywood...\n",
      "294294                                    ready first truth\n",
      "Name: body, Length: 294295, dtype: object\n",
      "0         massive big find really dig incriminating evid...\n",
      "1                         absofreakinglutely tear shit down\n",
      "2         joebwinner correct literally conservatives bur...\n",
      "3         factsrus guess that is cia operative killed china\n",
      "4                                     jenniewrennnn welcome\n",
      "                                ...                        \n",
      "294290    ok beautiful wife currently living free countr...\n",
      "294291                                 reckoning approaches\n",
      "294292    fuck piece shit fuck anyone disrespects countr...\n",
      "294293    thank ricky may loose good liberals hollywood ...\n",
      "294294                                    ready first truth\n",
      "Name: body, Length: 294295, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 14. Remove numbers from [body] of parleys (re = regular expression library)\n",
    "\n",
    "import re\n",
    "print(parler_df['body'])\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: ' '.join(re.sub(\"[^a-zA-Z]+\", \" \", x).split()))\n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2f87ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         massive big find really dig incriminating evid...\n",
      "1                         absofreakinglutely tear shit down\n",
      "2         joebwinner correct literally conservatives bur...\n",
      "3         factsrus guess that is cia operative killed china\n",
      "4                                     jenniewrennnn welcome\n",
      "                                ...                        \n",
      "294290    ok beautiful wife currently living free countr...\n",
      "294291                                 reckoning approaches\n",
      "294292    fuck piece shit fuck anyone disrespects countr...\n",
      "294293    thank ricky may loose good liberals hollywood ...\n",
      "294294                                    ready first truth\n",
      "Name: body, Length: 294295, dtype: object\n",
      "0         massive big find really dig incriminating evid...\n",
      "1                         absofreakinglutely tear shit down\n",
      "2         joebwinner correct literally conservative burn...\n",
      "3         factsrus guess that is cia operative killed china\n",
      "4                                     jenniewrennnn welcome\n",
      "                                ...                        \n",
      "294290    ok beautiful wife currently living free countr...\n",
      "294291                                   reckoning approach\n",
      "294292    fuck piece shit fuck anyone disrespect country...\n",
      "294293    thank ricky may loose good liberal hollywood s...\n",
      "294294                                    ready first truth\n",
      "Name: body, Length: 294295, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 15. Lemmatization of [body] of parleys (using WordNetLemmatizer from nltk) (ex: says => say) \n",
    "\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "print(parler_df['body'])\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: ' '.join([WordNetLemmatizer().lemmatize(w) for w in x.split()]))\n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4077e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         massive big find really dig incriminating evid...\n",
      "1                         absofreakinglutely tear shit down\n",
      "2         joebwinner correct literally conservative burn...\n",
      "3         factsrus guess that is cia operative killed china\n",
      "4                                     jenniewrennnn welcome\n",
      "                                ...                        \n",
      "294290    ok beautiful wife currently living free countr...\n",
      "294291                                   reckoning approach\n",
      "294292    fuck piece shit fuck anyone disrespect country...\n",
      "294293    thank ricky may loose good liberal hollywood s...\n",
      "294294                                    ready first truth\n",
      "Name: body, Length: 294295, dtype: object\n",
      "0         massive big find really dig incriminating evid...\n",
      "1                         absofreakinglutely tear shit down\n",
      "2         joebwinner correct literally conservative burn...\n",
      "3            factsrus guess that cia operative killed china\n",
      "4                                     jenniewrennnn welcome\n",
      "                                ...                        \n",
      "294290    beautiful wife currently living free country t...\n",
      "294291                                   reckoning approach\n",
      "294292    fuck piece shit fuck anyone disrespect country...\n",
      "294293    thank ricky may loose good liberal hollywood s...\n",
      "294294                                    ready first truth\n",
      "Name: body, Length: 294295, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 16. Remove words shorter than 3 characters from [body] of parleys\n",
    "\n",
    "print(parler_df['body'])\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: ' '.join([w.strip() for w in x.split() if len(w.strip()) >= 3]))\n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0b33385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of dataframe: (294295, 2)\n",
      "0         massive big find really dig incriminating evid...\n",
      "1                         absofreakinglutely tear shit down\n",
      "2         joebwinner correct literally conservative burn...\n",
      "3            factsrus guess that cia operative killed china\n",
      "4                                     jenniewrennnn welcome\n",
      "                                ...                        \n",
      "294290    beautiful wife currently living free country t...\n",
      "294291                                   reckoning approach\n",
      "294292    fuck piece shit fuck anyone disrespect country...\n",
      "294293    thank ricky may loose good liberal hollywood s...\n",
      "294294                                    ready first truth\n",
      "Name: body, Length: 294295, dtype: object\n",
      "\n",
      "Dimension of dataframe after preprocessing: (286237, 2)\n",
      "0         massive big find really dig incriminating evid...\n",
      "1                         absofreakinglutely tear shit down\n",
      "2         joebwinner correct literally conservative burn...\n",
      "3            factsrus guess that cia operative killed china\n",
      "4                                     jenniewrennnn welcome\n",
      "                                ...                        \n",
      "294290    beautiful wife currently living free country t...\n",
      "294291                                   reckoning approach\n",
      "294292    fuck piece shit fuck anyone disrespect country...\n",
      "294293    thank ricky may loose good liberal hollywood s...\n",
      "294294                                    ready first truth\n",
      "Name: body, Length: 286237, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 17. Filter out null values found in [body] of parleys once more = dimension reduction (rows)\n",
    "\n",
    "print('Dimension of dataframe: ' + str(parler_df.shape)) \n",
    "print(parler_df['body']) \n",
    "\n",
    "parler_df['body'].replace(\"\", np.nan, inplace=True)\n",
    "parler_df.dropna(subset=['body'], inplace=True)\n",
    "\n",
    "print('\\n'  + 'Dimension of dataframe after preprocessing: ' + str(parler_df.shape)) \n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0b1c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. Save pandas dataframe without index after preprocessing as CSV file\n",
    "\n",
    "parler_df.to_csv('parler_df_041_dates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f26a9674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of whole dataframe after preprocessing: (286237, 2)\n",
      "                                                     body createdAtformatted\n",
      "0       massive big find really dig incriminating evid...         2020-12-23\n",
      "1                       absofreakinglutely tear shit down         2021-01-03\n",
      "2       joebwinner correct literally conservative burn...         2020-11-24\n",
      "3          factsrus guess that cia operative killed china         2020-11-30\n",
      "4                                   jenniewrennnn welcome         2020-11-01\n",
      "...                                                   ...                ...\n",
      "294290  beautiful wife currently living free country t...         2020-12-15\n",
      "294291                                 reckoning approach         2020-12-05\n",
      "294292  fuck piece shit fuck anyone disrespect country...         2020-12-24\n",
      "294293  thank ricky may loose good liberal hollywood s...         2020-11-21\n",
      "294294                                  ready first truth         2020-12-20\n",
      "\n",
      "[286237 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cosmi\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\cosmi\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\cosmi\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of November dataframe after preprocessing: (164708, 2)\n",
      "                                                     body createdAtformatted\n",
      "2       joebwinner correct literally conservative burn...         2020-11-24\n",
      "3          factsrus guess that cia operative killed china         2020-11-30\n",
      "4                                   jenniewrennnn welcome         2020-11-01\n",
      "5                                         trumppin boomer         2020-11-23\n",
      "6       aintchaprecious captain debating team talk int...         2020-11-20\n",
      "...                                                   ...                ...\n",
      "294275                   devil worshipper michaelmichelle         2020-11-21\n",
      "294276  obviously buffoon idea electoral process work ...         2020-11-12\n",
      "294286                                    great awakening         2020-11-02\n",
      "294289                                               need         2020-11-26\n",
      "294293  thank ricky may loose good liberal hollywood s...         2020-11-21\n",
      "\n",
      "[164708 rows x 2 columns]\n",
      "Dimension of December dataframe after preprocessing: (93843, 2)\n",
      "                                                     body createdAtformatted\n",
      "0       massive big find really dig incriminating evid...         2020-12-23\n",
      "7                                     javaraz neanderthal         2020-12-16\n",
      "8                   snailman not fuck bro talk like nigga         2020-12-18\n",
      "9       jarthur thrown due lack evidence outstanding c...         2020-12-30\n",
      "14                          nottakingmyguns totally agree         2020-12-04\n",
      "...                                                   ...                ...\n",
      "294288  yay ted proud you especially since texas voted...         2020-12-07\n",
      "294290  beautiful wife currently living free country t...         2020-12-15\n",
      "294291                                 reckoning approach         2020-12-05\n",
      "294292  fuck piece shit fuck anyone disrespect country...         2020-12-24\n",
      "294294                                  ready first truth         2020-12-20\n",
      "\n",
      "[93843 rows x 2 columns]\n",
      "Dimension of January dataframe after preprocessing: (27686, 2)\n",
      "                                                     body createdAtformatted\n",
      "1                       absofreakinglutely tear shit down         2021-01-03\n",
      "23      repericswalwell see you want fuck huh bro know...         2021-01-07\n",
      "24       kteff nutshell people making got fucked tax deal         2021-01-02\n",
      "26        piercedxangel give address offered afraid bitch         2021-01-06\n",
      "31      godchild still talking not life thought decide...         2021-01-07\n",
      "...                                                   ...                ...\n",
      "294260                         mustwatchvideo second know         2021-01-02\n",
      "294261                                    petition recall         2021-01-01\n",
      "294278                             incompetent idiot fool         2021-01-05\n",
      "294282                           mob bos trafficking cult         2021-01-02\n",
      "294284  did not believe watch video president obama te...         2021-01-07\n",
      "\n",
      "[27686 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 19. Save pandas dataframes without index for each month after preprocessing as CSV file\n",
    "\n",
    "def check_month(date):\n",
    "    if (((date.split('-'))[0] == '2020') and ((date.split('-'))[1] == '11')):    # November 2020\n",
    "        return 'nov'\n",
    "    elif (((date.split('-'))[0] == '2020') and ((date.split('-'))[1] == '12')):  # December 2020\n",
    "        return 'dec'\n",
    "    else:\n",
    "        return 'jan' # January  2021\n",
    "       \n",
    "\n",
    "print('Dimension of whole dataframe after preprocessing: ' + str(parler_df.shape)) \n",
    "print(parler_df)\n",
    "\n",
    "parler_df['month'] = parler_df['createdAtformatted'].apply(check_month)\n",
    "\n",
    "parler_df_nov = parler_df[parler_df['month'] == 'nov']\n",
    "parler_df_nov.drop(['month'], inplace = True, axis = 1) \n",
    "print('Dimension of November dataframe after preprocessing: ' + str(parler_df_nov.shape)) \n",
    "print(parler_df_nov)\n",
    "\n",
    "parler_df_dec = parler_df[parler_df['month'] == 'dec']\n",
    "parler_df_dec.drop(['month'], inplace = True, axis = 1)  \n",
    "print('Dimension of December dataframe after preprocessing: ' + str(parler_df_dec.shape)) \n",
    "print(parler_df_dec)\n",
    "\n",
    "parler_df_jan = parler_df[parler_df['month'] == 'jan']  \n",
    "parler_df_jan.drop(['month'], inplace = True, axis = 1) \n",
    "print('Dimension of January dataframe after preprocessing: ' + str(parler_df_jan.shape)) \n",
    "print(parler_df_jan)\n",
    "\n",
    "parler_df_nov.to_csv('parler_df_041_dates_nov.csv', index=False)\n",
    "parler_df_dec.to_csv('parler_df_041_dates_dec.csv', index=False)\n",
    "parler_df_jan.to_csv('parler_df_041_dates_jan.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
